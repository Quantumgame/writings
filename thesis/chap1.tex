\chapter{Predicting Spikes and LFP from Acoustic Features}

\section{Acoustic Features Covary and Cluster}

Our goal was to describe the relationship between Zebra finch vocalizations, neuronal spiking, and the LFP. We segmented Zebra finch vocalizations and quantified them using a rich set of acoustic features. Syllables used in the analysis ranged in duration from 40ms to 400ms, which required us to quantify them so that the dimensionality of the feature vector that described a syllable was independent of duration. To achieve this, we quantified the statistical properties of the syllable power spectrum, amplitude envelope, and the time-varying fundamental, detailed in Methods - Acoustic Features. This produced a unique 19 dimensional feature vector for each syllable.
    In Figure 2, we show an example of the acoustic feature characterization for a single syllable, as well as examples of syllables that span the range of maximum amplitudes (Max A), mean spectral frequencies (Mean S) and saliencies (Saliency). Saliency is a measure of syllable “pitchiness”, low for noisy syllables and high for harmonic-stack-like syllables. These features, among several others, have been shown to be vital for determining the behavioral context, and hence semantic meaning, of Zebra finch vocalizations \cite{Elie2015b}.
    Acoustic features are intuitive quantities for describing syllables, but are not completely independent of each other. By construction, they naturally fall into three groups - those that describe the spectral distribution, the temporal distribution, and the time-varying fundamental frequency. Figure 3a shows a matrix of correlation coefficients between each acoustic feature. The features are ordered according to constructed group, but also naturally fall into several groups given the block-diagonal structure of the correlation matrix. Figure 3b shows a manually organized graphical representation of acoustic feature relationships. Edge thickness depicts the absolute value of the correlation coefficient, and coefficients less than 0.20 are not shown.
Taken together, the correlation matrix and graph show that acoustic features cluster into several groups. The time-varying fundamental features form one group (green in Figure 3b), with the inharmonic fundamental parameters Pk 2 and 2nd V forming a distinct subgroup. Features that describe fundamental frequency over time, the mean (Mean F0), max (Max F0), min (Min F0), and coefficient of variation (CV F0) are strongly correlated with each other. Purely spectral features, statistics computed from the power spectrum of the syllable, form another group (orange in Figure 3b). The mean spectral frequency (Mean S), 25th, 50th, and 75th percentiles of the spectral distribution (Q1, Q2, Q3, respectively), and the spectral skew formed a strongly correlated subgroup. The spectral kurtosis (Kurt S) was correlated to spectral standard deviation (Std T). The spectral entropy Ent S, a measure of inharmonicity, was strongly negatively correlated with Saliency - harmonic stack like syllables have low spectral entropies and high saliency, while noisy syllables have high entropies and low saliency. Both saliency and spectral entropy were correlated with spectral standard deviation and kurtosis. Quantities that describe purely temporal features were computed from the amplitude envelope and formed the last group (blue in Figure 3b). The mean and standard deviation of the amplitude envelope (not shown), were linearly proportional to syllable duration, with a correlation coefficient of 0.97. The entropy of the amplitude envelope, temporal entropy (Ent T), was strongly negatively correlated with maximum amplitude (Max A) - syllables with amplitude envelopes with high variation, such as Begging and Nest calls, also tended to have lower maximum amplitudes. Temporal skew (Skew T) and kurtosis (Kurt T) were correlated with each other but not much with other features.

\section{Spikes and LFP Driven by Amplitude, Temporal Entropy, Mean Spectral Frequency, Saliency}

We used an encoder approach to understand how acoustic features drive spike rate and LFP power. Figure 4 shows the isolation and extraction of features for syllables and the LFP. Acoustic feature extraction was described in the previous section. A syllable was isolated (Figure 4a), and the multi-electrode spike trains and LFP were taken for each of the ten trials the syllable was presented for (Figure 4c). The spike rate was computed for each trial, and averaged across trials. The power spectrum was computed from the LFP on each electrode for each trial, and the power spectra were averaged across trials to produce multi-electrode power spectra (Figure 4d). Performance of encoders and decoders for the LFP, described shortly, were contingent on first taking the log of the power spectra, and then z-scoring within electrode and frequency.
To quantify the univariate relationship between spike rates and acoustic features, and LFP power and acoustic features, we fit nonlinear tuning curves that estimated spike rate on a neuron or LFP power at a given electrode and frequency from each individual acoustic feature (Methods - Tuning Curve and Generalized Additive Encoder). Figure 5a shows example tuning curves for several acoustic features. The tuning curves illustrate that there are several basic relationships between acoustic features and spiking or LFP power. The top row shows example high performing tuning curves that predict neural response from syllable maximum amplitude (Max A). Strikingly, the neural response to amplitude is bimodal, some neurons respond to increases in amplitude by increasing their spike rate, while others decrease their spike rate. In contrast, the LFP power spectra on various electrodes did not exhibit the same bimodal relationship at low frequencies (0-16Hz and 33-49Hz bands), but did at high frequencies (165-182Hz band).
The second row of Figure 5a illustrates that the relationship between spike rate or LFP power and mean spectral frequency is multimodal and nonlinear. The tuning curves typically had a single peak (also called a “best frequency”) for spectral mean frequencies greater 2kHz. For neurons whose tuning curves predicted spike rate with a cross-validated R2 of 0.05 or above (n=367), 25\% had a best frequency less than 2.5kHz, and declined in spike rate as mean spectral frequency increased. The largest fraction of neurons had a best frequency between 2.5kHz and 3.5kHz (63\%), and a small fraction (0.11\%) had high best frequencies from 3.5kHz to 5kHz. The distribution of best frequencies had three peaks, one for neurons with low best frequencies (the lowest mean spectral frequency was around 2kHz), another peak at roughly 3kHz, and a third relatively small peak around 4kHz. Examination of the mean spectral frequency tuning curves for LFP power shows that for some electrodes, low frequencies (16-33Hz band) and high frequencies (165-182Hz band) exhibit multiple best frequencies as well.
Temporal entropy (Ent T) measures the disorder of the syllable amplitude envelope, and syllables with high temporal entropy elicit more spikes from neurons as shown in the third row of Figure 6a. LFP power had a multi-peaked relationship with temporal entropy. A similar relationship holds for pitch saliency (Saliency, last row). Syllables with high saliency, such as distance calls, are comprised of well-defined harmonic stacks and elicit a stronger spiking response than syllables with low pitch saliency, such as begging calls. LFP power exhibits a similar relationship, as saliency goes up, LFP power increases. The relationship between saliency and spike rate or LFP power was also multi-peaked for some neurons/electrodes.
The average performance for spike rate and LFP power at each frequency, for all acoustic features, is shown in Figure 5b. The highest performing tuning curves were for maximum amplitude (Max A), and they were most predictive for frequencies from 0-49Hz. Maximum amplitude was followed by highly correlated spectral features; mean spectral frequency (Mean S) was the second best predictor of activity, followed by spectral quartiles Q2 and Q1. Temporal entropy (Ent T) was also predictive of spike rate and LFP power, as well as the second voice feature (2nd V), a measure of syllable inharmonicity. With the exception of maximum amplitude and second voice, tuning curves that predicted spike rate well did best for predicting the 33-49Hz band.
    After fitting the tuning curves, we used them as input nonlinearities to a Generalized Additive Model that tried to predict spike rate or LFP power from all the nonlinearly mapped acoustic features. The performance for the encoders across frequencies for LFP power and for spike rate are shown in Figure 6c. To quantify the relationship between frequency, anatomical region, and multivariate encoder performace, a linear model was fit in R to predict the multivariate encoder R2 from frequency and region. Multivariate encoder performance was not highly predictable using this linear model (R2=0.06), but frequency bands had statistically significant differences (Table 1). Frequency bands from 16-49Hz had the highest relative predictability, with less predictability for higher frequencies. The only anatomical region that had a significant difference in predictability from other regions was NCM, which had a slightly lower predictability than CM and Field L1, L2, L3.


